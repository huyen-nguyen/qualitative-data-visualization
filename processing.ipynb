{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hope': {'type': 'VERB', 'count': 1}, 'gain': {'type': 'VERB', 'count': 1}, 'course': {'type': 'NOUN', 'count': 1}, 'broad': {'type': 'ADJ', 'count': 1}, 'datum': {'type': 'NOUN', 'count': 2}, 'understanding': {'type': 'NOUN', 'count': 1}, 'way': {'type': 'NOUN', 'count': 1}, 'can': {'type': 'VERB', 'count': 1}, 'use': {'type': 'VERB', 'count': 1}, 'professional': {'type': 'ADJ', 'count': 1}, 'world': {'type': 'NOUN', 'count': 1}}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import csv\n",
    "\n",
    "text = \"What I am hoping to gain from this course is a broader data understanding of data and the ways in which we can use it in the professional world.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     print(chunk.text)\n",
    "\n",
    "verbs = set()\n",
    "\n",
    "words = {}\n",
    "\n",
    "for token in doc:\n",
    "    if (token.pos_ == \"VERB\" or token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"ADV\"):\n",
    "        verbs.add(token.lemma_)\n",
    "        if token.lemma_ in words:\n",
    "            words[token.lemma_][\"count\"] += 1\n",
    "        else:\n",
    "            words[token.lemma_] = {}\n",
    "            words[token.lemma_][\"type\"] = token.pos_\n",
    "            words[token.lemma_][\"count\"] = 1\n",
    "            \n",
    "print(words)\n",
    "\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#             token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"something\",\"lot\",\"a\", \"an\", \"what\",\"the\",\"i\",\"it\",\"me\",\"my\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"whose\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"will\",\"would\",\"should\",\"can\",\"could\",\"ought\",\"i'm\",\"you're\",\"he's\",\"she's\",\"it's\",\"we're\",\"they're\",\"i've\",\"you've\",\"we've\",\"they've\",\"i'd\",\"you'd\",\"he'd\",\"she'd\",\"we'd\",\"they'd\",\"i'll\",\"you'll\",\"he'll\",\"she'll\",\"we'll\",\"they'll\",\"isn't\",\"aren't\",\"wasn't\",\"weren't\",\"hasn't\",\"haven't\",\"hadn't\",\"doesn't\",\"don't\",\"didn't\",\"won't\",\"wouldn't\",\"shan't\",\"shouldn't\",\"can't\",\"cannot\",\"couldn't\",\"mustn't\",\"let's\",\"that's\",\"who's\",\"what's\",\"here's\",\"there's\",\"when's\",\"where's\",\"why's\",\"how's\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"upon\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"say\",\"says\",\"said\",\"shall\",\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"1\" # from 1 to 9\n",
    "lemmaDict = dict()\n",
    "\n",
    "def removeStopwords(text):\n",
    "    doc = nlp(text)\n",
    "    output = \"\"\n",
    "    for chunk in doc.noun_chunks:\n",
    "        arr = chunk.text.lower().split()\n",
    "        res = []\n",
    "        for term in arr:\n",
    "            if not (term in stopwords):\n",
    "                res.append(term)\n",
    "        joinedStr = \" \".join(res).strip()\n",
    "        if (len(joinedStr) > 0):\n",
    "            output+= joinedStr + \",\"\n",
    "    return(output)\n",
    "\n",
    "\n",
    "with open(\"data/vis-journal-data.csv\", mode='r', encoding=\"latin-1\") as csv_in:\n",
    "    csv_reader = csv.DictReader(csv_in)                           \n",
    "    for index,row in enumerate(csv_reader):\n",
    "        if (row[\"JournalEntryWeek\"] == question):\n",
    "            removeStopwords(row[\"ResponseOnly\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write nounchunks to files for every response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Write nounchunks to file -----------\n",
    "\n",
    "with open('data/vis-journal-data.csv','r') as csvinput:\n",
    "    with open('data/vis-noun-data.csv', 'w') as csvoutput:\n",
    "        writer = csv.writer(csvoutput, lineterminator='\\n')\n",
    "        reader = csv.reader(csvinput)\n",
    "\n",
    "        all = []\n",
    "        row = next(reader)\n",
    "        row.append('Nounchunks')\n",
    "        all.append(row)\n",
    "\n",
    "        for row in reader:\n",
    "            row.append(removeStopwords(row[7]))\n",
    "            all.append(row)\n",
    "\n",
    "        writer.writerows(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = 'didnâ\\x80\\x99t'\n",
    "'â' in str1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'start': {'type': 'VERB', 'count': 4},\n",
       " 'datum': {'type': 'NOUN', 'count': 17},\n",
       " 'visualization': {'type': 'NOUN', 'count': 14},\n",
       " 'curious': {'type': 'ADJ', 'count': 2},\n",
       " 'quarter': {'type': 'NOUN', 'count': 2},\n",
       " 'would': {'type': 'VERB', 'count': 1},\n",
       " 'look': {'type': 'VERB', 'count': 3},\n",
       " 'could': {'type': 'VERB', 'count': 1},\n",
       " 'apply': {'type': 'VERB', 'count': 1},\n",
       " 'job': {'type': 'NOUN', 'count': 2},\n",
       " 'future': {'type': 'ADJ', 'count': 1},\n",
       " 'may': {'type': 'VERB', 'count': 1},\n",
       " 'want': {'type': 'VERB', 'count': 4},\n",
       " 'pursue': {'type': 'VERB', 'count': 1},\n",
       " 'take': {'type': 'VERB', 'count': 2},\n",
       " 'learn': {'type': 'VERB', 'count': 5},\n",
       " 'feel': {'type': 'VERB', 'count': 2},\n",
       " 'relevant': {'type': 'ADJ', 'count': 1},\n",
       " 'many': {'type': 'ADJ', 'count': 1},\n",
       " 'industry': {'type': 'NOUN', 'count': 1},\n",
       " 'fun': {'type': 'ADJ', 'count': 2},\n",
       " 'try': {'type': 'VERB', 'count': 1},\n",
       " 'figure': {'type': 'VERB', 'count': 1},\n",
       " 'good': {'type': 'ADJ', 'count': 1},\n",
       " 'way': {'type': 'NOUN', 'count': 4},\n",
       " 'present': {'type': 'VERB', 'count': 2},\n",
       " 'know': {'type': 'VERB', 'count': 5},\n",
       " 'will': {'type': 'VERB', 'count': 3},\n",
       " 'use': {'type': 'VERB', 'count': 4},\n",
       " 'new': {'type': 'ADJ', 'count': 2},\n",
       " 'skill': {'type': 'NOUN', 'count': 1},\n",
       " 'other': {'type': 'ADJ', 'count': 2},\n",
       " 'see': {'type': 'VERB', 'count': 2},\n",
       " 'place': {'type': 'NOUN', 'count': 1},\n",
       " 'lense': {'type': 'NOUN', 'count': 1},\n",
       " 'familiar': {'type': 'ADJ', 'count': 2},\n",
       " 'data': {'type': 'NOUN', 'count': 4},\n",
       " 'limit': {'type': 'VERB', 'count': 1},\n",
       " 'understanding': {'type': 'NOUN', 'count': 3},\n",
       " 'think': {'type': 'VERB', 'count': 8},\n",
       " 'more': {'type': 'ADJ', 'count': 4},\n",
       " 'nuanced': {'type': 'ADJ', 'count': 1},\n",
       " 'occur': {'type': 'VERB', 'count': 1},\n",
       " 'high': {'type': 'ADJ', 'count': 1},\n",
       " 'school': {'type': 'NOUN', 'count': 1},\n",
       " 'robotic': {'type': 'NOUN', 'count': 1},\n",
       " 'team': {'type': 'NOUN', 'count': 1},\n",
       " 'assume': {'type': 'VERB', 'count': 1},\n",
       " 'need': {'type': 'VERB', 'count': 2},\n",
       " 'include': {'type': 'VERB', 'count': 1},\n",
       " 'much': {'type': 'ADJ', 'count': 2},\n",
       " 'information': {'type': 'NOUN', 'count': 4},\n",
       " 'possible': {'type': 'ADJ', 'count': 1},\n",
       " 'argue': {'type': 'VERB', 'count': 1},\n",
       " 'relevance': {'type': 'NOUN', 'count': 1},\n",
       " 'expect': {'type': 'VERB', 'count': 2},\n",
       " 'opposite': {'type': 'NOUN', 'count': 1},\n",
       " 'case': {'type': 'NOUN', 'count': 1},\n",
       " 'essential': {'type': 'ADJ', 'count': 1},\n",
       " 'clear': {'type': 'ADJ', 'count': 1},\n",
       " 'precise': {'type': 'ADJ', 'count': 1},\n",
       " 'communication': {'type': 'NOUN', 'count': 1},\n",
       " 'interesting': {'type': 'ADJ', 'count': 1},\n",
       " 'learning': {'type': 'NOUN', 'count': 1},\n",
       " 'reasoning': {'type': 'NOUN', 'count': 1},\n",
       " 'certain': {'type': 'ADJ', 'count': 2},\n",
       " 'graph': {'type': 'NOUN', 'count': 1},\n",
       " 'well': {'type': 'ADJ', 'count': 1},\n",
       " 'communicate': {'type': 'VERB', 'count': 1},\n",
       " 'practicality': {'type': 'NOUN', 'count': 1},\n",
       " 'design': {'type': 'NOUN', 'count': 2},\n",
       " 'aesthetic': {'type': 'NOUN', 'count': 1},\n",
       " 'like': {'type': 'VERB', 'count': 1},\n",
       " 'numeric': {'type': 'ADJ', 'count': 1},\n",
       " 'presentation': {'type': 'NOUN', 'count': 3},\n",
       " 'oppose': {'type': 'VERB', 'count': 1},\n",
       " 'artistic': {'type': 'ADJ', 'count': 1},\n",
       " 'visual': {'type': 'ADJ', 'count': 3},\n",
       " 'cool': {'type': 'ADJ', 'count': 3},\n",
       " 'lovechild': {'type': 'NOUN', 'count': 1},\n",
       " 'idea': {'type': 'NOUN', 'count': 1},\n",
       " 'interdisciplinary': {'type': 'ADJ', 'count': 1},\n",
       " 'practice': {'type': 'NOUN', 'count': 1},\n",
       " 'exist': {'type': 'VERB', 'count': 1},\n",
       " 'statistic': {'type': 'NOUN', 'count': 2},\n",
       " 'understand': {'type': 'VERB', 'count': 3},\n",
       " 'important': {'type': 'ADJ', 'count': 4},\n",
       " 'notice': {'type': 'VERB', 'count': 1},\n",
       " 'do': {'type': 'VERB', 'count': 1},\n",
       " 'research': {'type': 'NOUN', 'count': 3},\n",
       " 'group': {'type': 'NOUN', 'count': 1},\n",
       " 'discussion': {'type': 'NOUN', 'count': 1},\n",
       " 'sure': {'type': 'ADJ', 'count': 2},\n",
       " 'change': {'type': 'VERB', 'count': 7},\n",
       " 'warm': {'type': 'VERB', 'count': 2},\n",
       " 'stripe': {'type': 'NOUN', 'count': 5},\n",
       " 'warming': {'type': 'NOUN', 'count': 4},\n",
       " 'make': {'type': 'VERB', 'count': 1},\n",
       " 'able': {'type': 'ADJ', 'count': 1},\n",
       " 'conversation': {'type': 'NOUN', 'count': 1},\n",
       " 'global': {'type': 'ADJ', 'count': 1},\n",
       " 'climate': {'type': 'NOUN', 'count': 5},\n",
       " 'find': {'type': 'VERB', 'count': 3},\n",
       " 'online': {'type': 'NOUN', 'count': 1},\n",
       " 'say': {'type': 'VERB', 'count': 3},\n",
       " 'few': {'type': 'ADJ', 'count': 2},\n",
       " 'half': {'type': 'NOUN', 'count': 1},\n",
       " 'harm': {'type': 'VERB', 'count': 1},\n",
       " 'simple': {'type': 'ADJ', 'count': 1},\n",
       " 'easy': {'type': 'ADJ', 'count': 1},\n",
       " 'people': {'type': 'NOUN', 'count': 1},\n",
       " 'believe': {'type': 'VERB', 'count': 1},\n",
       " 'real': {'type': 'ADJ', 'count': 1},\n",
       " 'problem': {'type': 'NOUN', 'count': 2},\n",
       " 'view': {'type': 'VERB', 'count': 1},\n",
       " 'stat': {'type': 'NOUN', 'count': 1},\n",
       " 'colour': {'type': 'NOUN', 'count': 1},\n",
       " 'code': {'type': 'VERB', 'count': 4},\n",
       " 'love': {'type': 'VERB', 'count': 1},\n",
       " 'great': {'type': 'ADJ', 'count': 1},\n",
       " 'thing': {'type': 'NOUN', 'count': 1},\n",
       " 'go': {'type': 'VERB', 'count': 2},\n",
       " 'depth': {'type': 'NOUN', 'count': 1},\n",
       " 'explanation': {'type': 'NOUN', 'count': 1},\n",
       " 'realise': {'type': 'VERB', 'count': 1},\n",
       " 'efficient': {'type': 'ADJ', 'count': 1},\n",
       " 'visualisation': {'type': 'NOUN', 'count': 1},\n",
       " 'can': {'type': 'VERB', 'count': 3},\n",
       " 'join': {'type': 'VERB', 'count': 1},\n",
       " 'class': {'type': 'NOUN', 'count': 3},\n",
       " 'little': {'type': 'ADJ', 'count': 1},\n",
       " 'peek': {'type': 'ADJ', 'count': 1},\n",
       " 'realm': {'type': 'NOUN', 'count': 1},\n",
       " 'coding': {'type': 'NOUN', 'count': 2},\n",
       " 'tie': {'type': 'VERB', 'count': 1},\n",
       " 'moment': {'type': 'NOUN', 'count': 1},\n",
       " 'realize': {'type': 'VERB', 'count': 1},\n",
       " 'mean': {'type': 'VERB', 'count': 1},\n",
       " 'produce': {'type': 'VERB', 'count': 1},\n",
       " 'graphs': {'type': 'ADJ', 'count': 1},\n",
       " 'give': {'type': 'VERB', 'count': 3},\n",
       " 'beginning': {'type': 'NOUN', 'count': 1},\n",
       " 'course': {'type': 'NOUN', 'count': 3},\n",
       " 'tool': {'type': 'NOUN', 'count': 2},\n",
       " 'move': {'type': 'VERB', 'count': 2},\n",
       " 'most': {'type': 'ADJ', 'count': 1},\n",
       " 'experience': {'type': 'NOUN', 'count': 1},\n",
       " 'relate': {'type': 'VERB', 'count': 1},\n",
       " 'alter': {'type': 'VERB', 'count': 1},\n",
       " 'html': {'type': 'NOUN', 'count': 1},\n",
       " 'myspace': {'type': 'NOUN', 'count': 1},\n",
       " 'tumblr': {'type': 'NOUN', 'count': 1},\n",
       " 'set': {'type': 'NOUN', 'count': 1},\n",
       " 'portray': {'type': 'VERB', 'count': 1},\n",
       " 'pleasing': {'type': 'ADJ', 'count': 1},\n",
       " 'opinion': {'type': 'NOUN', 'count': 1},\n",
       " 'whole': {'type': 'ADJ', 'count': 1},\n",
       " 'lot': {'type': 'NOUN', 'count': 1},\n",
       " 'strong': {'type': 'ADJ', 'count': 2},\n",
       " 'grasp': {'type': 'NOUN', 'count': 2},\n",
       " 'determine': {'type': 'VERB', 'count': 1},\n",
       " 'test': {'type': 'NOUN', 'count': 1},\n",
       " 'run': {'type': 'VERB', 'count': 1},\n",
       " 'base': {'type': 'VERB', 'count': 1},\n",
       " 'structure': {'type': 'NOUN', 'count': 3},\n",
       " 'paper': {'type': 'NOUN', 'count': 2},\n",
       " 'write': {'type': 'VERB', 'count': 1},\n",
       " 'knowledge': {'type': 'NOUN', 'count': 1},\n",
       " 'r': {'type': 'NOUN', 'count': 2},\n",
       " 'refresh': {'type': 'VERB', 'count': 1},\n",
       " 'enhance': {'type': 'VERB', 'count': 1},\n",
       " 'book': {'type': 'NOUN', 'count': 1},\n",
       " 'benefit': {'type': 'VERB', 'count': 1},\n",
       " 'search': {'type': 'VERB', 'count': 1},\n",
       " 'face': {'type': 'VERB', 'count': 1},\n",
       " 'answer': {'type': 'NOUN', 'count': 2},\n",
       " 'complete': {'type': 'ADJ', 'count': 1},\n",
       " 'solidify': {'type': 'VERB', 'count': 1},\n",
       " 'contextualization': {'type': 'NOUN', 'count': 1},\n",
       " 'concept': {'type': 'NOUN', 'count': 1},\n",
       " 'actual': {'type': 'ADJ', 'count': 1},\n",
       " 'analysis': {'type': 'NOUN', 'count': 1},\n",
       " 'slow': {'type': 'ADJ', 'count': 1},\n",
       " 'pace': {'type': 'NOUN', 'count': 1},\n",
       " 'process': {'type': 'NOUN', 'count': 1},\n",
       " 'couple': {'type': 'NOUN', 'count': 1},\n",
       " 'week': {'type': 'NOUN', 'count': 1},\n",
       " 'resourceful': {'type': 'ADJ', 'count': 1},\n",
       " 'motivated': {'type': 'ADJ', 'count': 1},\n",
       " 'fact': {'type': 'NOUN', 'count': 1},\n",
       " 'choose': {'type': 'VERB', 'count': 1},\n",
       " 'capable': {'type': 'ADJ', 'count': 1},\n",
       " 'outcome': {'type': 'NOUN', 'count': 1},\n",
       " 'unsure': {'type': 'ADJ', 'count': 1},\n",
       " 'prepared': {'type': 'ADJ', 'count': 1},\n",
       " 'skilled': {'type': 'ADJ', 'count': 1},\n",
       " 'question': {'type': 'NOUN', 'count': 1},\n",
       " 'person': {'type': 'NOUN', 'count': 1},\n",
       " 'life': {'type': 'NOUN', 'count': 1}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getWordsFromJournal(index):\n",
    "    allWords = \"\"\n",
    "    words = {}\n",
    "    \n",
    "    print(index)\n",
    "    # get data from vis journal\n",
    "    with open(\"data/vis-journal-data.csv\", mode='r', encoding=\"latin-1\") as csv_journal:\n",
    "        csv_reader = csv.DictReader(csv_journal) \n",
    "        for row in csv_reader:\n",
    "            # select answer from such index\n",
    "            if (row[\"JournalEntryWeek\"] == str(index)):\n",
    "                allWords += row[\"ResponseOnly\"]\n",
    "        \n",
    "        doc = nlp(allWords)\n",
    "        \n",
    "        # 4 comma type\n",
    "        for token in doc:\n",
    "            if (token.pos_ == \"VERB\" or token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\"):\n",
    "                if (\"â\" in token.lemma_):\n",
    "                    continue\n",
    "                thisLemma = token.lemma_.replace(\"'\", \"\")\n",
    "                if token.lemma_ in words:\n",
    "                    words[thisLemma][\"count\"] += 1\n",
    "                else:\n",
    "                    words[thisLemma] = {}\n",
    "                    words[thisLemma][\"type\"] = token.pos_\n",
    "                    words[thisLemma][\"count\"] = 1\n",
    "\n",
    "    return words       \n",
    "        \n",
    "getWordsFromJournal(\"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "with open('data/prompt.csv','r') as csvinput:\n",
    "    with open('data/vis-word-data.csv', 'w') as csvoutput:\n",
    "        writer = csv.writer(csvoutput)\n",
    "\n",
    "        for row in csv.reader(csvinput):\n",
    "            if row[2] == \"JournalEntryWeek\":\n",
    "                writer.writerow(row+[\"Words\"])\n",
    "            else:\n",
    "                writer.writerow(row+[str(getWordsFromJournal(row[2]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "a\n",
      "b\n",
      "c\n",
      "2\n",
      "a\n",
      "b\n",
      "c\n",
      "3\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "num_list = [1, 2, 3]\n",
    "alpha_list = ['a', 'b', 'c']\n",
    "\n",
    "for number in num_list:\n",
    "    print(number)\n",
    "    for letter in alpha_list:\n",
    "        print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hoping', 'gain', 'course', 'broader', 'understanding', 'data']\n"
     ]
    }
   ],
   "source": [
    "str1 = \"What I am hoping to gain from this course is a broader understanding of data and\"\n",
    "arr = str1.lower().split()\n",
    "res = []\n",
    "\n",
    "for term in (arr):\n",
    "    if not (term in stopwords):\n",
    "        res.append(term)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
